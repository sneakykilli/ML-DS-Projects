{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5373178,"sourceType":"datasetVersion","datasetId":3117560},{"sourceId":7953459,"sourceType":"datasetVersion","datasetId":4665511}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-27T05:49:50.446602Z","iopub.execute_input":"2024-03-27T05:49:50.447552Z","iopub.status.idle":"2024-03-27T05:49:51.811500Z","shell.execute_reply.started":"2024-03-27T05:49:50.447508Z","shell.execute_reply":"2024-03-27T05:49:51.810293Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/500k-chatgpt-tweets-jan-mar-2023/Twitter Jan Mar.csv\n/kaggle/input/edgetier-takehome/labled_1.csv\n/kaggle/input/edgetier-takehome/active_learning_labled - reinforced_learning.csv\n/kaggle/input/edgetier-takehome/labled_2.csv\n/kaggle/input/edgetier-takehome/labled_3.csv\n/kaggle/input/edgetier-takehome/df_higher_quality.csv\n/kaggle/input/edgetier-takehome/bert_zeroshot (1).csv\n/kaggle/input/edgetier-takehome/tweets_clean.npy\n/kaggle/input/edgetier-takehome/bert_zero_shot_non-technical.csv\n/kaggle/input/edgetier-takehome/multinomial_nb_model.pkl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AIM: Build a Binary Classifier Model to Detect Technical Content in Tweets.\n\n### Action Plan\nIdentifying technical content within a vast dataset of 500k tweets posed challenges. Traditional methods such as keyword and hashtag analysis yielded only 1% relevant tweets. We refined the dataset to 200k tweets and employed BERTopic to identify potential technical tweets, resulting in 440 candidates. These were manually reviewed to ensure accuracy, leading to a balanced dataset of 800 tweets with a 50/50 split between technical and non-technical content. We then built a Naive Bayes classifier, continually improving it by incorporating human-labeled tweets with low model confidence for continuous learning.\n\n* **Step 1: Identifying Potentially Technical Tweets with BERT Zero-Shot Classification**  \n    - Filtered out tweets with excessive links or mentions, resulting in a refined dataset of 200,000 tweets.\n    - Employed BERTopic (zero-shot classification) with an 85% probability threshold, identifying 440 candidate technical tweets for manual verification.\n\n* **Step 2: Creating a Training/Test Set for Naive Bayes Classifier from Labeled BERT Data**  \n    - Manually reviewed candidate tweets to correct any misclassifications.\n    - Constructed a balanced dataset of 800 tweets with equal representation of technical and non-technical content.\n\n* **Step 3: Training Initial Model on Labeled Data from BERT & Manual Review**  \n    - Trained a Naïve Bayes classifier for efficient and interpretable results, reserving 15% of labeled tweets for testing.\n\n* **Step 4: Developing Functions for Active Learning**  \n    - Built three functions to facilitate the active learning process, ensuring we did not sample from data previously used to train the Naive Bayes Model.\n\n* **Step 5: Active Learning Iterations**  \n    - Reviewed and labeled tweets with low confidence scores (55%-75%), incorporating newly categorized data back into the model for continuous improvement.\n\n* **Step 6: Saving the Model to Hugging Face & Testing on Tweets**  \n    - Saved the model to Hugging Face and tested it on sample tweets.","metadata":{}},{"cell_type":"code","source":"!pip install bertopic\n!pip install joblib\n\nimport nltk\nfrom collections import Counter\nimport random\nimport re\nfrom textblob import TextBlob\nimport string\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\nfrom bertopic import BERTopic\nfrom bertopic.representation import KeyBERTInspired\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\n\nimport joblib","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-27T05:49:57.890126Z","iopub.execute_input":"2024-03-27T05:49:57.891114Z","iopub.status.idle":"2024-03-27T05:52:54.570777Z","shell.execute_reply.started":"2024-03-27T05:49:57.891080Z","shell.execute_reply":"2024-03-27T05:52:54.569660Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bertopic\n  Downloading bertopic-0.16.0-py2.py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.26.4)\nCollecting hdbscan>=0.8.29 (from bertopic)\n  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: umap-learn>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (0.5.5)\nRequirement already satisfied: pandas>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from bertopic) (2.2.1)\nRequirement already satisfied: scikit-learn>=0.22.2.post1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (1.2.2)\nRequirement already satisfied: tqdm>=4.41.1 in /opt/conda/lib/python3.10/site-packages (from bertopic) (4.66.1)\nCollecting sentence-transformers>=0.4.1 (from bertopic)\n  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: plotly>=4.7.0 in /opt/conda/lib/python3.10/site-packages (from bertopic) (5.18.0)\nCollecting cython<3,>=0.27 (from hdbscan>=0.8.29->bertopic)\n  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.1 kB)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\nRequirement already satisfied: joblib>=1.0 in /opt/conda/lib/python3.10/site-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.5->bertopic) (2023.4)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (8.2.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from plotly>=4.7.0->bertopic) (21.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.38.2)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.2+cpu)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.21.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers>=0.4.1->bertopic) (9.5.0)\nRequirement already satisfied: numba>=0.51.2 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\nRequirement already satisfied: pynndescent>=0.5 in /opt/conda/lib/python3.10/site-packages (from umap-learn>=0.5.0->bertopic) (0.5.11)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.9.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->plotly>=4.7.0->bertopic) (3.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\nDownloading bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\nBuilding wheels for collected packages: hdbscan\n  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=819466 sha256=232c986a17e0c9403e00ead9957a5e9a6202662f8f3e9f2b3cbcbf0b3bbc8ce0\n  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\nSuccessfully built hdbscan\nInstalling collected packages: cython, hdbscan, sentence-transformers, bertopic\n  Attempting uninstall: cython\n    Found existing installation: Cython 3.0.8\n    Uninstalling Cython-3.0.8:\n      Successfully uninstalled Cython-3.0.8\nSuccessfully installed bertopic-0.16.0 cython-0.29.37 hdbscan-0.8.33 sentence-transformers-2.6.1\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (1.3.2)\n","output_type":"stream"},{"name":"stderr","text":"2024-03-27 05:52:30.795521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-27 05:52:30.795751: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-27 05:52:30.977142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the CSV file containing tweet data\ndf = pd.read_csv('/kaggle/input/500k-chatgpt-tweets-jan-mar-2023/Twitter Jan Mar.csv')\n\n# Define a set of keywords that might indicate technical content\nsimple_keyword_set = ['login', 'timeout', 'authentication', 'server']\n\n# Function to clean tweet text: lowercase, remove URLs, hashtags, and special characters\ndef clean_tweet(text):\n  text = text.lower()\n  text = re.sub(r'http\\S+', '', text)  # Remove URLs\n  text = re.sub(r'[@#]', '', text)     # Remove mentions and hashtags\n  text = re.sub(r\"(?P<url>http[s]?:\\/\\/[^\\s]+)\", \"\", text)  # Remove remaining URLs with more complex patterns\n  return text\n\n# Function to check if a tweet contains a link\ndef contains_link(text):\n  url_pattern = r'https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'  # Regular expression for URL detection\n  if re.search(url_pattern, text):\n    return 1  # Tweet contains a link\n  else:\n    return 0  # Tweet does not contain a link\n\n# Function to search for simple keywords in the tweet text\ndef simple_keyword_search(text):\n  for word in simple_keyword_set:\n    if word in text:\n      return 1  # Keyword found in the text\n      break  # Exit the loop if a keyword is found\n  else:\n    return 0  # No keywords found\n\n# Function to perform stemming on text (reduce words to their base form)\ndef stem_text(text):\n  stemmer = PorterStemmer()  # Import PorterStemmer class from nltk (assuming it's installed)\n  stemmed_text = stemmer.stem(text)\n  return stemmed_text\n\n# Preprocess the tweet content column\ndf['content'] = df['content'].astype(str).str.lower()  # Ensure content is string and lowercase\ndf['tweet_cleaned'] = df['content'].apply(clean_tweet)\ndf['stem'] = df['tweet_cleaned'].apply(stem_text)  # Apply stemming (optional)\n\n# Add new features to the dataframe based on the content\ndf['contains_link'] = df['content'].apply(contains_link)\ndf['tweet_length'] = df['content'].str.len()  # Character length of the tweet\ndf['num_hashtags'] = df['content'].str.split('#').str.len() - 1  # Number of hashtags (excluding the first occurrence)\ndf['num_mentions'] = df['content'].str.split('@').str.len() - 1  # Number of mentions (excluding the first occurrence)\n\n# Search for simple keywords in the cleaned tweet text\ndf['contains_keyword'] = df['tweet_cleaned'].apply(simple_keyword_search)\n\n# Calculate percentage and total count of tweets containing keywords\npercent_contains_keyword = (df['contains_keyword'].sum() / len(df['contains_keyword'])) * 100\ntotal_num_containing = df['contains_keyword'].sum()\n\n# Print informative message about the analysis results\nprint(f\"\"\"\nA Total of {total_num_containing} Tweets contain keywords that May indicate the content is Technical in Nature \nThis accounts for {percent_contains_keyword:.2f}% of Total Tweets.\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:34:43.670619Z","iopub.execute_input":"2024-03-27T02:34:43.671433Z","iopub.status.idle":"2024-03-27T02:35:29.669038Z","shell.execute_reply.started":"2024-03-27T02:34:43.671399Z","shell.execute_reply":"2024-03-27T02:35:29.667741Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nA Total of 1987 Tweets contain keywords that May indicate the content is Technical in Nature \nThis accounts for 0.40% of Total Tweets.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 1: Identifying Potentially Technical Tweets with BERT Zero-Shot Classification\n\nOur Dataset contains a lot of Tweets that are pretty spammy in nature & won't be super useful for our Model. I want to initially filter out Tweets that May be spammy in Nature (Containing links, or lots of Tags/Mentions) and use this higher Quality Dataframe with BERTopic's ZeroShot classification ot find Tweets that BERT model believes are Technical in nature:\n\n* **Strategy:**\n    1. **Filter High-Quality Tweets:** \n        * Create a subset of tweets focusing on potentially more informative content:\n            * Exclude tweets containing links (potentially less textual information).\n            * Select tweets with a minimum length of 20 characters (potentially more substance).\n            * Limit tweets with excessive hashtags or mentions (potentially less focused content).\n    2. **Feature Engineering:**\n        * Extract two text representations for each tweet within the high-quality subset:\n            * **Basic Processing:** Lowercase text, apply stemming, remove stop words, and tokenize.\n            * **Advanced Processing:** Perform all steps from basic processing, additionally removing hashtags and mentions while preserving the overall sentence structure.\n    3. **BERT Zero-Shot Classification:**\n        * Utilize these text representations as input for BERT's Zero-Shot classification. \n        * This approach leverages cosine similarity to categorize text snippets based on predefined labels (e.g., \"technical\", \"non-technical\").\n        * The goal is to identify the text representation (basic vs. advanced processing) that yields the most accurate classification for technical tweets.\n\nBy focusing on high-quality tweets and exploring different text representations, we aim to improve the accuracy of identifying potentially technical tweets using BERT Zero-Shot classification. ","metadata":{}},{"cell_type":"code","source":"# Define criteria for identifying higher quality tweets\ndf_higher_quality = df[(df['contains_link'] == 0) & (df['tweet_length'] > 20) & (df['num_hashtags'] < 5) & (df['num_mentions'] < 5)]\n\n# Extract tweet IDs and dataframe indices for the higher quality tweets\nID_HIGH_QUALITY = df_higher_quality['id'].to_list()\nINDEX_HIGHER_QUALITY_TWEETS = df_higher_quality.index.to_list()\n\n# Set a random seed for reproducibility\nrandom.seed(42)\n\n# Get the total number of high-quality tweets\nnum_high_quality_tweets_ = len(INDEX_HIGHER_QUALITY_TWEETS)\n\n# Randomly sample half of the high-quality tweets for BERT zero-shot task\nINDEX_BERT_ZERO_SHOT = random.sample(INDEX_HIGHER_QUALITY_TWEETS, num_high_quality_tweets_ // 2)\n\n# Create a list of indices for unused high-quality tweets (remaining half)\nINDEX_UNUSED = [item for item in INDEX_HIGHER_QUALITY_TWEETS if item not in INDEX_BERT_ZERO_SHOT]\n\n# Create a dataframe containing the tweets selected for BERT zero-shot task\ndf_bert_zeroshot = df.iloc[INDEX_BERT_ZERO_SHOT]\n\n# Save the dataframe to make it easier to come back to. \n# df_bert_zeroshot.to_csv('bert_zeroshot.csv', index=True)\n# df_higher_quality.to_csv('df_higher_quality.csv', index=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:35:39.665778Z","iopub.execute_input":"2024-03-27T02:35:39.666416Z","iopub.status.idle":"2024-03-27T02:41:16.001061Z","shell.execute_reply.started":"2024-03-27T02:35:39.666382Z","shell.execute_reply":"2024-03-27T02:41:15.999477Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load the pre-processed data for BERT zero-shot classification\ndf_bert_zeroshot = pd.read_csv('/kaggle/input/edgetier-takehome/bert_zeroshot (1).csv')\n\n# Extract the pre-processed text representations (cleaned and stemmed)\ndoc_stem = df_bert_zeroshot['stem']\ndoc_clean = df_bert_zeroshot['tweet_cleaned']\n\n# Define a list of example technical issue categories used for zero-shot classification\ntechnical_issue_categories_stem = [\n    \"login issue\",\n    \"error message\",\n    \"server issue\",\n    \"website issue\",\n]\n\n# Initialize BERTopic model with specific configurations\ntopic_model = BERTopic(\n    embedding_model=\"thenlper/gte-small\",  # Pre-trained language model for text embedding\n    min_topic_size=15,  # Minimum number of documents per topic\n    zeroshot_topic_list=technical_issue_categories_stem,  # List of categories for zero-shot classification\n    zeroshot_min_similarity=.85,  # Minimum cosine similarity threshold for assigning a zero-shot label\n    representation_model=KeyBERTInspired()  # Text representation model (optional)\n)\n\n# Fit the BERTopic model on the cleaned tweets\ntopics, _ = topic_model.fit_transform(doc_clean)\n\n# Define a function to convert zero-shot labels to \"Technical\" or \"Non-Technical\"\ndef zero_shot_to_label(text):\n    if text in technical_issue_categories_stem:\n        text = 'Technical'\n    else:\n        text = 'Non-Technical'\n    return text\n\n# Apply the zero_shot_to_label function to create a new \"label\" column for classification\ndf_bert_zeroshot['zero_shot_label'] = topic_model.get_document_info(doc_clean)['Name']\ndf_bert_zeroshot['label'] = df_bert_zeroshot['zero_shot_label'].apply(zero_shot_to_label)\n\n# Filter dataframes based on the assigned labels\ndf_bert_technical = df_bert_zeroshot[df_bert_zeroshot['label'] == 'Technical']\ndf_bert_non_technical = df_bert_zeroshot[df_bert_zeroshot['label'] == 'Non-Technical']\n\n# Calculate and print informative statistics about the zero-shot classification results\ntotal_sample = len(doc_clean)\ntotal_labled_technical = df_bert_technical['label'].count()\npercent_labled_technical = (len(df_bert_technical['label']) / len(df_bert_zeroshot['label'])) * 100\n\nprint(f\"\"\"\nWe fed BERT {total_sample} embeddings from our original 500K Tweet Dataset. \nA Total of {total_labled_technical} Tweets were categorised as Technical.\nThis accounts for {percent_labled_technical:.2f}% of Total Tweets in the Batch we fed the pre-trained Model.\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2024-03-27T05:56:59.408289Z","iopub.execute_input":"2024-03-27T05:56:59.410711Z","iopub.status.idle":"2024-03-27T06:33:29.193540Z","shell.execute_reply.started":"2024-03-27T05:56:59.410643Z","shell.execute_reply":"2024-03-27T06:33:29.192196Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a87d7d1deec4f32a045f42532d6366c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d88915c50c4ed990da55062c7a57de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc949b7cc945458286093233af03ef2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e3d0fd99bf4a459c5638245cd0da42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/66.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf21f12baa054d29a15c7685447967a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"746063c608f14cf18f335d2c01069939"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c51fa05ae347f8be88a5411b3c4356"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef2762bd63742669e051ea22db9c567"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b55546ba5cc4c758762dbcdc00f7344"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d65472bbbff34298a1eed6bddae707ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f8973e41d8048018c6d22deb4ec27cd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid = os.fork()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\nWe fed BERT 92266 embeddings from our original 500K Tweet Dataset. \nA Total of 263 Tweets were categorised as Technical.\nThis accounts for 0.29% of Total Tweets in the Batch we fed the pre-trained Model.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the classified dataframes to separate CSV files to make process a little easier\n\n# DataFrame containing tweets classified as 'Technical' (potentially require further labeling)\n# df_bert_technical.to_csv('bert_zero_shot_unlabled.csv', index=False)\n\n# DataFrame containing tweets classified as 'Non-Technical'\n# df_bert_non_technical.to_csv('bert_zero_shot_non-technical.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T02:06:56.780954Z","iopub.execute_input":"2024-03-26T02:06:56.781302Z","iopub.status.idle":"2024-03-26T02:06:59.367564Z","shell.execute_reply.started":"2024-03-26T02:06:56.781275Z","shell.execute_reply":"2024-03-26T02:06:59.366554Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Turn our Labled BERT Data into a Training / Test Set for Naive Bayes classifier\n\nThis section loads the dataframes required for training the Naive Bayes model and performs some initial cleaning steps.\n\n* **Load Dataframes:** We load two dataframes:\n    * `df_labled_active_learning`: This dataframe contains tweets that have been labeled as technical or non-technical (potentially through an initial active learning process).\n    * `df_bert_non_technical`: This dataframe contains tweets identified as non-technical using BERT zero-shot classification.\n* **Balance the Dataset:** We aim for a balanced dataset with an equal number of technical and non-technical tweets. The script calculates the number of technical tweets and the number of non-technical tweets needed to achieve this balance.\n* **Sample Non-Technical Tweets:** Randomly samples tweets from the `df_bert_non_technical` dataframe to reach the desired balance.\n* **Combine Data:** Creates a new dataframe `df_bayes` by combining the labeled data and the sampled non-technical tweets.\n* **Optional Text Preprocessing:** Defines a function `preprocess` for text cleaning (tokenization, stop word removal, stemming). This step might be redundant depending on the pre-processing applied to `df_labled_active_learning` and `df_bert_non_technical`.  ","metadata":{}},{"cell_type":"code","source":"# Load the updated dataframes after manual correction\n#   * Active learning labeled data (potentially containing both technical and non-technical tweets)\ndf_labled_active_learning = pd.read_csv('/kaggle/input/edgetier-takehome/active_learning_labled - reinforced_learning.csv')\n\n#   * Non-technical tweets identified using BERT zero-shot classification\ndf_bert_non_technical = pd.read_csv('/kaggle/input/edgetier-takehome/bert_zero_shot_non-technical.csv')\n\n# Calculate the number of technical tweets in the active learning data\ntechnical_count = (df_labled_active_learning['label'] == 'Technical').sum()\n\n# Determine the number of non-technical tweets needed to balance the dataset\nnon_technical_needed = len(df_labled_active_learning) - technical_count\n\n# Sample non-technical tweets randomly (set a seed for reproducibility)\nrandom.seed(42)\nrandom_sample_non_tech = random.sample(df_bert_non_technical['id'].to_list(), non_technical_needed)\n\n# Create a dataframe containing the sampled non-technical tweets\ndf_bert_non_technical_ = df_bert_non_technical[df_bert_non_technical['id'].isin(random_sample_non_tech)]\n\n# Combine data for training the Naive Bayes classifier\nid_ = df_labled_active_learning['id'].to_list() + random_sample_non_tech\ncontent_ = df_labled_active_learning['content'].to_list() + df_bert_non_technical_['content'].to_list()\ntweet_clean_ = df_labled_active_learning['tweet_cleaned'].to_list() + df_bert_non_technical_['tweet_cleaned'].to_list()\nstem_ = df_labled_active_learning['stem'].to_list() + df_bert_non_technical_['stem'].to_list()\nlabel_ = df_labled_active_learning['label'].to_list() + df_bert_non_technical_['label'].to_list()\n\n# Create a new dataframe (df_bayes) to store the combined data\ndf_bayes = pd.DataFrame(\n{\n    'id': id_,\n    'content': content_,\n    'tweet_cleaned': tweet_clean_,\n    'stem': stem_,\n    'label': label_\n}\n)\n\n# Define a function for text pre-processing (optional, might be redundant)\ndef preprocess(text):\n    tokens = word_tokenize(text)\n    tokens = [token for token in tokens if token not in string.punctuation]\n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token.lower() not in stop_words and token.lower() != \"'s\"]\n    stemmer = PorterStemmer()\n    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n    stemmed_text = ' '.join(stemmed_tokens)\n    return stemmed_text\n\n# Apply pre-processing to the 'tweet_cleaned' column (might be redundant)\n#  Finally! we have a dataset containing 50% Technical Tweets and 50% non-Technical we can Train a Naive Bayes classifier on\ndf_bayes['preprocess'] = df_bayes['tweet_cleaned'].apply(preprocess)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:47:15.016326Z","iopub.execute_input":"2024-03-27T02:47:15.016858Z","iopub.status.idle":"2024-03-27T02:47:16.868878Z","shell.execute_reply.started":"2024-03-27T02:47:15.016789Z","shell.execute_reply":"2024-03-27T02:47:16.867482Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Train Initial Model on Labled Data from BERT & Manual Review\n\nThis section prepares the data for training, trains a Naive Bayes model, and evaluates its performance on an unseen test set.\n\n* **Split Data:** Splits the combined data in `df_bayes['preprocess']` (preprocessed text) and `df_bayes['label']` (labels) into training and testing sets using `train_test_split`. The test size is set to 15%.\n* **TF-IDF Vectorizer:** Creates a TF-IDF vectorizer to convert textual features into numerical features. TF-IDF considers both the frequency of a word in a document and its overall frequency in the corpus, potentially helping to highlight important terms.\n* **Train Vectorizer:** Fits the vectorizer on the training data (`X_train_features`). This helps the vectorizer learn the importance of words in the context of classifying tweets as technical or non-technical.\n* **Transform Data:** Transforms the training and testing data using the fitted vectorizer. This converts the text data into numerical features suitable for the Naive Bayes model.\n* **Naive Bayes Model:** Creates a Multinomial Naive Bayes model for classification.\n* **Train Model:** Trains the Naive Bayes model (`model_bayes`) using the TF-IDF features of the training data (`X_train_features`) and the corresponding labels (`y_train`).\n* **Make Predictions:** Uses the trained model to predict labels for the unseen test data (`X_test_features`).\n* **Evaluate Performance:** Calculates the accuracy score and classification report to assess the model's performance on the test set. The classification report provides a more detailed breakdown of the model's performance for each class (technical/non-technical).\n","metadata":{}},{"cell_type":"code","source":"# Split data into training and testing sets (85% train, 15% test)\nX_train, X_test, y_train, y_test = train_test_split(df_bayes['preprocess'], df_bayes['label'], test_size=0.15, random_state=42)\n\n# Create a Multinomial Naive Bayes model for classification\nmodel_bayes = MultinomialNB()\n\n# Create a TF-IDF vectorizer to convert text data to numerical features\nvectorizer = TfidfVectorizer()\n\n# Train the vectorizer on the training data (learns word importance)\nX_train_features = vectorizer.fit_transform(X_train)\n\n# Transform the test data using the fitted vectorizer\nX_test_features = vectorizer.transform(X_test)\n\n# Train the Naive Bayes model using the TF-IDF features\nmodel_bayes.fit(X_train_features, y_train)\n\n# Make predictions on the unseen test data using the trained model\ny_pred = model_bayes.predict(X_test_features)\n\n# Evaluate model performance\naccuracy_0 = accuracy_score(y_test, y_pred)\nclass_report_0 = classification_report(y_test, y_pred)\n\nprint(f\"Accuracy of the Naive Bayes model: {accuracy_0:.4f}\")\nprint(\"Classification Report:\")\nprint(class_report_0)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:48:18.332360Z","iopub.execute_input":"2024-03-27T02:48:18.333507Z","iopub.status.idle":"2024-03-27T02:48:18.375020Z","shell.execute_reply.started":"2024-03-27T02:48:18.333459Z","shell.execute_reply":"2024-03-27T02:48:18.373869Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Accuracy of the Naive Bayes model: 0.6400\nClassification Report:\n               precision    recall  f1-score   support\n\nNon-Technical       1.00      0.25      0.40        24\n    Technical       0.59      1.00      0.74        26\n\n     accuracy                           0.64        50\n    macro avg       0.80      0.62      0.57        50\n weighted avg       0.79      0.64      0.58        50\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 4: Build a Few functions to make Active Learning easier\n\n**Functions for incorporating human feedback and iteratively improving model performance**\n\n### `get_random_tweets_train(num_tweets)`\n\n* **Purpose:** Retrieves a random sample of tweets from a higher quality dataframe for active learning.\n* **Arguments:** \n    - `num_tweets`: Number of tweets to sample.\n* **Steps:**\n    1. Identifies available tweet IDs from the higher quality dataframe.\n    2. Randomly samples the specified number of tweets.\n    3. Creates a dataframe containing the sampled tweets.\n    4. Applies text pre-processing to the `'tweet_cleaned'` column.\n    5. Updates a global list of sampled IDs to avoid duplicates in future retrievals.\n* **Return:** Dataframe containing randomly sampled tweets with preprocessed text.\n\n### `run_prediction_new_df(df, confidence_score)`\n\n* **Purpose:** Predicts labels (technical/non-technical) and confidence scores for a new dataframe of tweets.\n* **Arguments:** \n    - `df`: Dataframe containing tweets for prediction.\n    - `confidence_score`: Threshold for confidence in predictions.\n* **Steps:**\n    1. Preprocesses the `'tweet_cleaned'` column in the new dataframe.\n    2. Converts preprocessed text to features using the fitted vectorizer.\n    3. Predicts labels using the Naive Bayes model.\n    4. Predicts probability scores for each class (technical/non-technical).\n    5. Adds predicted labels and confidence scores as new columns in the dataframe.\n    6. Identifies tweets with confidence scores below the threshold for either class.\n* **Return:** Dataframe containing predictions, confidence scores, and tweets recommended for further labeling.\n\n### `add_more_labeled_model(df)`\n\n* **Purpose:** Retrain the model with newly labeled data and evaluate performance.\n* **Arguments:** \n    - `df`: Dataframe containing newly labeled tweets.\n* **Steps:**\n    1. Preprocesses the `'tweet_cleaned'` column in the new labeled data.\n    2. Incorporates the new preprocessed text and labels into the existing training data.\n    3. Converts the combined training data into features using the fitted vectorizer.\n    4. Retrains the Naive Bayes model using the updated training data.\n    5. Makes predictions on the existing test set using the retrained model.\n    6. Evaluates the retrained model's performance on the test set.\n* **Return:** Accuracy score and classification report for the retrained model.\n","metadata":{}},{"cell_type":"code","source":"# Function to get random tweets for training (active learning)\ndef get_random_tweets_train(num_tweets):\n\n    \"\"\"\n    This function retrieves a random sample of tweets from a higher quality dataframe \n    (potentially containing more reliable labels) for active learning.\n\n    Args:\n        num_tweets (int): The desired number of tweets to sample.\n\n    Returns:\n        pandas.DataFrame: A dataframe containing the randomly sampled tweets with preprocessed text.\n    \"\"\"\n\n    global ids_sampled  # Assuming this variable keeps track of already sampled IDs\n\n    # Identify available IDs from the higher quality data that haven't been used yet\n    ids_available = [item for item in df_higher_quality['id'].to_list() \n                     if item not in df_bayes['id'].to_list() or item not in ids_sampled]\n\n    # Sample the desired number of tweets randomly from the available IDs\n    random_sample_high_quality = random.sample(ids_available, num_tweets)\n\n    # Create a dataframe containing the sampled tweets\n    df_random_tweets_train = df_higher_quality[df_higher_quality['id'].isin(random_sample_high_quality)]\n\n    # Apply pre-processing to the 'tweet_cleaned' column in the new dataframe\n    df_random_tweets_train['preprocess'] = df_random_tweets_train['tweet_cleaned'].apply(preprocess)\n\n    # Update the list of sampled IDs to avoid duplicates in future retrievals\n    ids_sampled += random_sample_high_quality\n\n    return df_random_tweets_train\n\n\n# Function to predict labels and confidence scores for a new dataframe\ndef run_prediction_new_df(df, confidence_score):\n\n    \"\"\"\n    This function predicts labels (technical/non-technical) and confidence scores \n    for a new dataframe containing tweets.\n\n    Args:\n        df (pandas.DataFrame): The dataframe containing tweets for prediction.\n        confidence_score (float): The threshold for confidence in predictions.\n\n    Returns:\n        pandas.DataFrame: A dataframe containing the predicted labels, confidence scores, \n                         and tweets requiring further labeling based on the confidence threshold.\n    \"\"\"\n\n    # Apply pre-processing to the 'tweet_cleaned' column in the new dataframe\n    df['preprocess'] = df['tweet_cleaned'].apply(preprocess)\n\n    # Convert preprocessed text to features using the fitted vectorizer\n    X_new_features_ = vectorizer.transform(df['preprocess'])\n\n    # Predict labels (technical/non-technical) for the new tweets\n    y_new_pred_ = model_bayes.predict(X_new_features_)\n\n    # Predict probability scores for each class (technical/non-technical)\n    y_new_proba_ = model_bayes.predict_proba(X_new_features_)\n    # Convert the probability scores to a list\n    y_new_proba_ = [item for item in y_new_proba_]\n\n    # Add predicted labels and confidence scores as new columns in the dataframe\n    df['prediction'] = y_new_pred_\n    df['confidenct_non_tech'] = [item[0] for item in y_new_proba_]  # Confidence in non-technical\n    df['confidenct_tech'] = [item[1] for item in y_new_proba_]  # Confidence in technical\n\n    # Identify tweets where the confidence score is below the threshold for either class\n    to_label_df = df[\n        ((df['prediction'] == 'Technical') & (df['confidenct_tech'] < confidence_score)) |\n        ((df['prediction'] == 'Non-Technical') & (df['confidenct_non_tech'] < confidence_score))\n    ]\n\n    # Return the dataframe containing predictions, confidence scores, and tweets for further labeling\n    return to_label_df\n\ndef add_more_labeled_model(df):\n\n    \"\"\"\n    This function incorporates newly labeled data into the training data \n    and retrains the Naive Bayes model. It also evaluates the model performance \n    on the existing test set after retraining.\n\n    Args:\n        df (pandas.DataFrame): The dataframe containing newly labeled tweets.\n\n    Returns:\n        float: The accuracy score of the retrained model on the test set.\n        str: The classification report for the retrained model on the test set.\n    \"\"\"\n\n    global current_X_train, current_y_train  # Assuming these store current training data\n\n    # Apply text pre-processing to the 'tweet_cleaned' column in the new labeled data\n    df['preprocess'] = df['tweet_cleaned'].apply(preprocess)\n\n    # Concatenate the new preprocessed text with existing training features\n    new_X_train = pd.concat([current_X_train, df['preprocess']], ignore_index=True)\n\n    # Concatenate the new labels with existing training labels\n    new_y_train = pd.concat([current_y_train, df['label']], ignore_index=True)\n\n    # Convert the combined training data into features using the fitted vectorizer\n    new_X_train_features = vectorizer.transform(new_X_train)\n\n    # No need to transform the test data again, it's already transformed (assuming X_test_features is defined elsewhere)\n\n    # Retrain the Naive Bayes model using the updated training data\n    model_bayes.fit(new_X_train_features, new_y_train)\n\n    # Update the global variables to store the new training data for future retraining\n    current_X_train = new_X_train\n    current_y_train = new_y_train\n\n    # Make predictions on the existing test set using the retrained model\n    y_pred = model_bayes.predict(X_test_features)\n\n    # Evaluate the performance of the retrained model on the test set\n    accuracy = accuracy_score(y_test, y_pred)\n    class_report = classification_report(y_test, y_pred)\n\n    # Return the accuracy score and classification report for the retrained model\n    return accuracy, class_report\n","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:51:12.063651Z","iopub.execute_input":"2024-03-27T02:51:12.064287Z","iopub.status.idle":"2024-03-27T02:51:12.082223Z","shell.execute_reply.started":"2024-03-27T02:51:12.064253Z","shell.execute_reply":"2024-03-27T02:51:12.080986Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Step 5: Active Learning Iterations\n**Use the trained Naive Bayes Model to predict Tweet categories on Random Tweets from the High Quality List, manually Label any Tweet with a low confidence score & plug that Tweet into the Model for retraining**\n\n1. **Sample Tweets:** The `get_random_tweets_train` function retrieves a random sample of tweets from a higher quality dataframe (potentially containing more reliable labels). This helps focus on potentially informative examples, especially when dealing with imbalanced datasets.\n\n2. **Predict Labels and Confidence Scores:** The `run_prediction_new_df` function predicts labels (technical/non-technical) and confidence scores for the sampled tweets. A confidence score threshold is used to identify tweets where the model is less certain about its prediction. These tweets are considered good candidates for human labeling as they have the potential to significantly improve the model's performance.\n\n3. **Manual Labeling:** The tweets identified in step 2 (potentially saved to a CSV file) are presented for manual labeling. This human intervention helps provide more reliable labels for these uncertain tweets.\n\n4. **Retrain Model:** The `add_more_labeled_model` function incorporates the newly labeled data from step 3 into the existing training data. This enriched training data is then used to retrain the Naive Bayes model.\n\n5. **Evaluate Performance:** The performance of the retrained model is evaluated on the existing test set using metrics like accuracy and classification report. This helps assess the effectiveness of the active learning loop in improving the model's ability to classify tweets correctly.","metadata":{}},{"cell_type":"code","source":"# List to store IDs of tweets already sampled for active learning\nids_sampled = []\n\n# Global variables to store current training data for the Naive Bayes model\ncurrent_X_train = X_train\ncurrent_y_train = y_train","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:48:49.593654Z","iopub.execute_input":"2024-03-27T02:48:49.594428Z","iopub.status.idle":"2024-03-27T02:48:49.601164Z","shell.execute_reply.started":"2024-03-27T02:48:49.594381Z","shell.execute_reply":"2024-03-27T02:48:49.599732Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Sample 1000 tweets from the higher quality data for active learning\ndf_random_tweets_train_1 = get_random_tweets_train(1000)\n\n# Predict labels and confidence scores for the sampled tweets\ndf_to_label_1 = run_prediction_new_df(df_random_tweets_train_1, 0.55)\n\n# # Optionally, save the tweets requiring labeling for manual review (commented out)\n# df_to_label_1.to_csv('to_label_1.csv')\n\n# Read the manually labeled data (presumably from 'to_label_1.csv' or similar source)\ndf_labeled_1 = pd.read_csv('/kaggle/input/edgetier-takehome/labled_1.csv')\n\n# Retrain the Naive Bayes model with the newly labeled data\naccuracy_1, class_report_1 = add_more_labeled_model(df_labeled_1)\n\n# Print the accuracy score and classification report for the retrained model\nprint(accuracy_1)\nprint(class_report_1)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:51:23.475942Z","iopub.execute_input":"2024-03-27T02:51:23.476491Z","iopub.status.idle":"2024-03-27T02:51:31.455849Z","shell.execute_reply.started":"2024-03-27T02:51:23.476440Z","shell.execute_reply":"2024-03-27T02:51:31.454658Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"0.72\n               precision    recall  f1-score   support\n\nNon-Technical       0.63      1.00      0.77        24\n    Technical       1.00      0.46      0.63        26\n\n     accuracy                           0.72        50\n    macro avg       0.82      0.73      0.70        50\n weighted avg       0.82      0.72      0.70        50\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sample 1000 tweets from the higher quality data for active learning (iteration 2)\ndf_random_tweets_train_2 = get_random_tweets_train(1000)\n\n# Predict labels and confidence scores for the sampled tweets (iteration 2)\ndf_to_label_2 = run_prediction_new_df(df_random_tweets_train_2, 0.65)\n\n# # Optionally, save the tweets requiring labeling for manual review (commented out)\n# df_to_label_2.to_csv('to_label_2.csv')\n\n# Read the manually labeled data (presumably from 'to_label_2.csv' or similar source)\ndf_labeled_2 = pd.read_csv('/kaggle/input/edgetier-takehome/labled_2.csv')\n\n# Retrain the Naive Bayes model with the newly labeled data (iteration 2)\naccuracy_2, class_report_2 = add_more_labeled_model(df_labeled_2)\n\n# Print the accuracy score and classification report for the retrained model (iteration 2)\nprint(accuracy_2)\nprint(class_report_2)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:51:43.128783Z","iopub.execute_input":"2024-03-27T02:51:43.129290Z","iopub.status.idle":"2024-03-27T02:51:50.572031Z","shell.execute_reply.started":"2024-03-27T02:51:43.129255Z","shell.execute_reply":"2024-03-27T02:51:50.570755Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.66\n               precision    recall  f1-score   support\n\nNon-Technical       0.59      1.00      0.74        24\n    Technical       1.00      0.35      0.51        26\n\n     accuracy                           0.66        50\n    macro avg       0.79      0.67      0.63        50\n weighted avg       0.80      0.66      0.62        50\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sample 1000 tweets from the higher quality data for active learning (iteration 3)\ndf_random_tweets_train_3 = get_random_tweets_train(1000)\n\n# Predict labels and confidence scores for the sampled tweets (iteration 3)\ndf_to_label_3 = run_prediction_new_df(df_random_tweets_train_3, 0.60)\n\n# Save the tweets requiring labeling for manual review (iteration 3)\ndf_to_label_3.to_csv('to_label_3.csv')\n\n# Read the manually labeled data (presumably from 'to_label_3.csv')\ndf_labeled_3 = pd.read_csv('/kaggle/input/edgetier-takehome/labled_3.csv')\n\n# Retrain the Naive Bayes model with the newly labeled data (iteration 3)\naccuracy_3, class_report_3 = add_more_labeled_model(df_labeled_3)\n\n# Print the accuracy score and classification report for the retrained model (iteration 3)\nprint(accuracy_3)\nprint(class_report_3)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:51:59.942696Z","iopub.execute_input":"2024-03-27T02:51:59.943372Z","iopub.status.idle":"2024-03-27T02:52:07.404142Z","shell.execute_reply.started":"2024-03-27T02:51:59.943315Z","shell.execute_reply":"2024-03-27T02:52:07.402775Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0.64\n               precision    recall  f1-score   support\n\nNon-Technical       0.57      1.00      0.73        24\n    Technical       1.00      0.31      0.47        26\n\n     accuracy                           0.64        50\n    macro avg       0.79      0.65      0.60        50\n weighted avg       0.79      0.64      0.59        50\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Step 6: Save the Model the Model, Read it back it & test on some Tweets\n**The Test set is relativley small, after a few iterations of Active Learning it looks like the Model is doing a pretty good job recognising Technical Tweets, Let's see how it performs on some fresh Tweets**","metadata":{}},{"cell_type":"code","source":"# Save the model to a file\njoblib.dump(model_bayes, 'multinomial_nb_model.pkl')\n\n# Read the model back in\nloaded_model = joblib.load('/kaggle/input/edgetier-takehome/multinomial_nb_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-03-27T02:57:50.830811Z","iopub.execute_input":"2024-03-27T02:57:50.831228Z","iopub.status.idle":"2024-03-27T02:57:50.842886Z","shell.execute_reply.started":"2024-03-27T02:57:50.831194Z","shell.execute_reply":"2024-03-27T02:57:50.841769Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"['multinomial_nb_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"def predict_category(text):\n    model = loaded_model\n    preprocessed_text = preprocess(text)\n    vectorized_text = vectorizer.transform([preprocessed_text])\n    category = model.predict(vectorized_text)\n    \n    return category[0]\n\ntweets_non_technical = [\n    \"I'm constantly amazed by how cool ChatGPT is! It's like having a conversation with a genius.\",\n    \"ChatGPT never fails to impress me with its capabilities. It's simply awesome!\",\n    \"Just had the most amazing conversation with ChatGPT. It's mind-blowing how smart it is!\",\n    \"Every time I use ChatGPT, I'm reminded of how advanced AI technology has become. Truly fascinating!\",\n    \"ChatGPT is so cool! It's like having a virtual assistant that knows everything.\",\n    \"I can't get over how cool ChatGPT is. It's like having a super-intelligent friend to chat with!\",\n    \"Using ChatGPT feels like peeking into the future. It's incredible what AI can do!\",\n    \"Just had an enlightening conversation with ChatGPT. It's seriously impressive!\",\n    \"ChatGPT never ceases to amaze me. It's like having a personal AI companion.\",\n    \"Can we just take a moment to appreciate how cool ChatGPT is? It's revolutionizing the way we interact with AI!\"\n]\n\ntweets_technical = [\n    \"ChatGPT's server is down, so frustrating!\",\n    \"Having trouble logging into ChatGPT. Is anyone else experiencing this issue?\",\n    \"Is it just me or is ChatGPT server down right now? I need it for work!\",\n    \"Tried logging into ChatGPT multiple times but it's not working. What's going on?\",\n    \"Getting error messages when trying to access ChatGPT. This is frustrating.\",\n    \"Unable to log in to ChatGPT. Keep getting a 'server error' message.\",\n    \"ChatGPT seems to be server down. Can't access my conversations.\",\n    \"Anyone else having issues with ChatGPT? I keep getting a connection timeout error.\",\n    \"Need to use ChatGPT urgently but it's not loading. What's going on?\",\n    \"Just when I need ChatGPT the most, it's down. Seriously frustrating!\"\n] \n\nfor tweet in tweets_non_technical:\n    print(predict_category(tweet))\n    \nfor tweet in tweets_technical:\n    print(predict_category(tweet))","metadata":{"execution":{"iopub.status.busy":"2024-03-27T03:16:58.526475Z","iopub.execute_input":"2024-03-27T03:16:58.528105Z","iopub.status.idle":"2024-03-27T03:16:58.585627Z","shell.execute_reply.started":"2024-03-27T03:16:58.528053Z","shell.execute_reply":"2024-03-27T03:16:58.584711Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Non-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nNon-Technical\nTechnical\nTechnical\nTechnical\nTechnical\nTechnical\nTechnical\nTechnical\nNon-Technical\nNon-Technical\nNon-Technical\n","output_type":"stream"}]}]}